{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "sns.set_theme()\n",
    "from tensorflow import keras\n",
    "\n",
    "from constants import TRAINING_PARTITIONS, ALL_PARTITIONS, annotation_mapping, amino_acid_mapping, reverse_annotation_mapping\n",
    "from constants import TYPES, KINGDOMS, METRIC_KINGDOMS, METRIC_TYPES\n",
    "from metrics.metrics import *\n",
    "from utils.Dataset import Dataset\n",
    "from utils.helpers import getDatasetPath\n",
    "from utils.encoding import categoricalToSequence, oneHotToCategorical, sequenceToCategorical, categoricalToOneHot\n",
    "from serialization import Serializer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "run_timestamp = \"20211113-0233\"\n",
    "base_path = f\"../results/{run_timestamp}/\"\n",
    "cv_models = {}\n",
    "for k in TRAINING_PARTITIONS:\n",
    "    cv_models[k] = keras.models.load_model(base_path + f\"models/holdout-fold_{k}_final.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bootstrap"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def getRelevantData(df: pd.DataFrame, query: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    relevant_data = df.query(query)\n",
    "    y_pred = np.array([sequenceToCategorical(seq, annotation_mapping) for seq in relevant_data[\"prediction\"]])\n",
    "    y_true = np.array([sequenceToCategorical(seq, annotation_mapping) for seq in relevant_data[\"annotation\"]])\n",
    "\n",
    "    return (y_pred, y_true)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def binarize(array: np.ndarray, label: int) -> np.ndarray:\n",
    "    binarized = array.copy()\n",
    "    binarized[array == label] = 1\n",
    "    binarized[array != label] = 0\n",
    "\n",
    "    return binarized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def bootstrap(test_data: pd.DataFrame, num_bootstraps: int):\n",
    "    bootstraps = {i: test_data.sample(frac=1, replace=True, axis=0) for i in range(num_bootstraps)}\n",
    "\n",
    "    metrics = [MCC(), Recall(\"macro\"), Precision(\"macro\")]\n",
    "    metrics_dict = {}\n",
    "    for i in tqdm(range(num_bootstraps), leave=False, desc=\"Excluding overall metrics\"):\n",
    "        metrics_dict[i] = {}\n",
    "        for metric in metrics:\n",
    "            # All sequences\n",
    "            y_pred, y_true = getRelevantData(bootstraps[i], \"index == index\")\n",
    "            metrics_dict[i][metric.name] = {\n",
    "                \"overall\": {\n",
    "                    \"overall\": metric(y_true, y_pred)\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # By kingdom\n",
    "            for kingdom in KINGDOMS:\n",
    "                y_pred, y_true = getRelevantData(bootstraps[i], f\"kingdom == '{kingdom}'\")\n",
    "                metrics_dict[i][metric.name][\"overall\"][kingdom] = metric(y_true, y_pred)\n",
    "\n",
    "    # Manually exclude non-existing labels (L & T) from eukarya\n",
    "    for i in tqdm(range(num_bootstraps), leave=False, desc=\"Excluding non-existent pathways\"):\n",
    "        y_pred, y_true = getRelevantData(bootstraps[i], \"kingdom == 'EUKARYA'\")\n",
    "        metrics_dict[i][\"precision\"][\"overall\"][\"EUKARYA\"] = precision_score(y_true.flatten(), y_pred.flatten(), average=\"macro\", labels=[0,3,4,5])\n",
    "        metrics_dict[i][\"recall\"][\"overall\"][\"EUKARYA\"] = recall_score(y_true.flatten(), y_pred.flatten(), average=\"macro\", labels=[0,3,4,5])\n",
    "\n",
    "    # By label\n",
    "    for i in tqdm(range(num_bootstraps), leave=False, desc=\"Computing per-label metrics\"):\n",
    "        for label in range(6):\n",
    "            y_true, y_pred = getRelevantData(bootstraps[i], f\"index == index\")\n",
    "            y_true = binarize(y_true, label)\n",
    "            y_pred = binarize(y_pred, label)\n",
    "\n",
    "            metrics_dict[i][\"mcc\"][label] = {\"overall\": matthews_corrcoef(y_true.flatten(), y_pred.flatten())}\n",
    "            metrics_dict[i][\"precision\"][label] = {\"overall\": precision_score(y_true.flatten(), y_pred.flatten())}\n",
    "            metrics_dict[i][\"recall\"][label] = {\"overall\": recall_score(y_true.flatten(), y_pred.flatten())}\n",
    "\n",
    "    # By label x kingdom\n",
    "    for i in tqdm(range(num_bootstraps), leave=False, desc=\"Computing per-label & kingdom metrics\"):\n",
    "        for label in range(6):\n",
    "            for kingdom in KINGDOMS:\n",
    "                y_true, y_pred = getRelevantData(bootstraps[i], f\"kingdom == '{kingdom}'\")\n",
    "                y_true = binarize(y_true, label)\n",
    "                y_pred = binarize(y_pred, label)\n",
    "\n",
    "                metrics_dict[i][\"mcc\"][label][kingdom] = matthews_corrcoef(y_true.flatten(), y_pred.flatten())\n",
    "                metrics_dict[i][\"precision\"][label][kingdom] = precision_score(y_true.flatten(), y_pred.flatten())\n",
    "                metrics_dict[i][\"recall\"][label][kingdom] = recall_score(y_true.flatten(), y_pred.flatten())\n",
    "\n",
    "    return metrics_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing overall metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [02:38<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exlcluding non-existent pathways from eukarya...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing per-label metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [05:41<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing per-label & kingdom metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [05:12<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing overall metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [02:35<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exlcluding non-existent pathways from eukarya...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:29<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing per-label metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [05:34<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing per-label & kingdom metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [05:13<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing overall metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [02:34<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exlcluding non-existent pathways from eukarya...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:28<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing per-label metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [05:31<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing per-label & kingdom metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [05:07<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing overall metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [02:35<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exlcluding non-existent pathways from eukarya...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:29<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing per-label metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [05:42<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing per-label & kingdom metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [05:17<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "NUM_BOOTSTRAPS_PER_FOLD = 256\n",
    "\n",
    "cv_metrics_dict = {}\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "dataset = Dataset(getDatasetPath())\n",
    "for k, model in tqdm(cv_models.items(), desc=\"Fold progress\"):\n",
    "    test_data = dataset.getFolds([k])\n",
    "\n",
    "    test_x = np.array([categoricalToOneHot(sequenceToCategorical(seq, amino_acid_mapping), amino_acid_mapping) for seq in test_data[\"sequence\"]])\n",
    "    predictions = model.predict(test_x)\n",
    "    y_true = np.array([sequenceToCategorical(seq, annotation_mapping) for seq in test_data[\"annotation\"]])\n",
    "    y_pred = np.array([oneHotToCategorical(pred) for pred in predictions])\n",
    "\n",
    "    test_data[\"prediction\"] = np.array([categoricalToSequence(pred, reverse_annotation_mapping) for pred in y_pred])\n",
    "\n",
    "    cv_metrics_dict[k] = bootstrap(test_data, NUM_BOOTSTRAPS_PER_FOLD)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = {0: 'S', 1: 'T', 2: 'L', 3: 'I', 4: 'M', 5: 'O', \"overall\": \"overall\"}\n",
    "\n",
    "cv_final_metrics = pd.DataFrame([\n",
    "    (partition, bootstrap, metric, label_text, kingdom, cv_metrics_dict[partition][bootstrap][metric][label][kingdom])\n",
    "    for bootstrap in range(NUM_BOOTSTRAPS_PER_FOLD)\n",
    "    for partition in TRAINING_PARTITIONS\n",
    "    for metric in [\"mcc\", \"precision\", \"recall\"]\n",
    "    for label, label_text in labels.items()\n",
    "    for kingdom in METRIC_KINGDOMS\n",
    "])\n",
    "\n",
    "cv_final_metrics.columns = [\"holdout_fold\", \"bootstrap\", \"metric\", \"label\", \"kingdom\", \"value\"]\n",
    "cv_final_metrics.set_index([\"holdout_fold\", \"bootstrap\", \"metric\", \"label\", \"kingdom\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "        holdout_fold  bootstrap  metric    label   kingdom     value\n0                  1          0     mcc        S   EUKARYA  0.908898\n1                  1          0     mcc        S   ARCHAEA  0.696838\n2                  1          0     mcc        S  POSITIVE  0.769908\n3                  1          0     mcc        S  NEGATIVE  0.621653\n4                  1          0     mcc        S   overall  0.840507\n...              ...        ...     ...      ...       ...       ...\n107515             4        255  recall  overall   EUKARYA  0.869244\n107516             4        255  recall  overall   ARCHAEA  0.846012\n107517             4        255  recall  overall  POSITIVE  0.804781\n107518             4        255  recall  overall  NEGATIVE  0.869732\n107519             4        255  recall  overall   overall  0.867676\n\n[107520 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>holdout_fold</th>\n      <th>bootstrap</th>\n      <th>metric</th>\n      <th>label</th>\n      <th>kingdom</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>mcc</td>\n      <td>S</td>\n      <td>EUKARYA</td>\n      <td>0.908898</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>mcc</td>\n      <td>S</td>\n      <td>ARCHAEA</td>\n      <td>0.696838</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>mcc</td>\n      <td>S</td>\n      <td>POSITIVE</td>\n      <td>0.769908</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>mcc</td>\n      <td>S</td>\n      <td>NEGATIVE</td>\n      <td>0.621653</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>mcc</td>\n      <td>S</td>\n      <td>overall</td>\n      <td>0.840507</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>107515</th>\n      <td>4</td>\n      <td>255</td>\n      <td>recall</td>\n      <td>overall</td>\n      <td>EUKARYA</td>\n      <td>0.869244</td>\n    </tr>\n    <tr>\n      <th>107516</th>\n      <td>4</td>\n      <td>255</td>\n      <td>recall</td>\n      <td>overall</td>\n      <td>ARCHAEA</td>\n      <td>0.846012</td>\n    </tr>\n    <tr>\n      <th>107517</th>\n      <td>4</td>\n      <td>255</td>\n      <td>recall</td>\n      <td>overall</td>\n      <td>POSITIVE</td>\n      <td>0.804781</td>\n    </tr>\n    <tr>\n      <th>107518</th>\n      <td>4</td>\n      <td>255</td>\n      <td>recall</td>\n      <td>overall</td>\n      <td>NEGATIVE</td>\n      <td>0.869732</td>\n    </tr>\n    <tr>\n      <th>107519</th>\n      <td>4</td>\n      <td>255</td>\n      <td>recall</td>\n      <td>overall</td>\n      <td>overall</td>\n      <td>0.867676</td>\n    </tr>\n  </tbody>\n</table>\n<p>107520 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_final_metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Store results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "Serializer.save(cv_final_metrics, \"cv_metrics\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}